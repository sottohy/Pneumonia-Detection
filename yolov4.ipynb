{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alaa Ashraf 20208007\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Malak Medhat 20208031"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Donia Essam 20208011"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mariam Ahmad 20208042\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Menna Mahmoud 20208033"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPvi1NBhS3QT"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqZeKcmWT7v_"
      },
      "outputs": [],
      "source": [
        "csv_file = '/content/drive/MyDrive/yolov4/train_labels.csv'\n",
        "df = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28N9wNwiT-n_"
      },
      "source": [
        "After importing the necessary libraries, we read the train_labels.csv file and load it into a dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzhOQKV2blkS"
      },
      "source": [
        "# Converting .dcm files to .jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkKq1EQCUEkY"
      },
      "outputs": [],
      "source": [
        "# Converting dcm images to jpg\n",
        "\n",
        "train_path = '/content/drive/MyDrive/uni/dataset/train_images'\n",
        "output_train_path = '/content/drive/MyDrive/uni/Output/train'\n",
        "\n",
        "def convert(row,folder_path,output_path):\n",
        "    file = os.path.join(folder_path, f\"{row['patientId']}.dcm\")\n",
        "    print(file)\n",
        "      # Check if the file exists\n",
        "    if not os.path.isfile(file):\n",
        "          print(f\"File not found: {file}\")\n",
        "          return\n",
        "    image = pydicom.dcmread(file) # reading the dcm file using dcmread\n",
        "    image = image.pixel_array  # extracting the image pixels data from the read dcm\n",
        "    image = cv2.resize(image, (224,224))  # resizing the images\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) # converting them to rgb\n",
        "    out_path = os.path.join(output_path, f\"{row['patientId']}.jpg\")  # specifying the output path as the patientId.jpg\n",
        "    cv2.imwrite(out_path, image)  # writing the image into the output path\n",
        "\n",
        "for _ , row in df.iterrows(): # returns index and the content of each row\n",
        "    convert(row,train_path,output_train_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJnBUkpYUUHz"
      },
      "source": [
        "We create a convert function which converts the dcm files to jpg by giving it a row from the train_labels.csv file, getting the patientId from it (which corresponds to a file name in the dcm folder), and converting it to a jpg file. We used dcmread from pydicom to convert it into an image, then we resize the images and convert them to RGB. We then create an image with the same patientId name using cv2 imwrite. We itterate over all the rows from the csv file and convert the corresponding images if patientId is in this way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGptmlkyWaZc"
      },
      "outputs": [],
      "source": [
        "images_folder = '/content/drive/MyDrive/data2/test'\n",
        "dcm_path = '/content/drive/MyDrive/uni/dataset/test_images'\n",
        "\n",
        "# Converting the dcm test files to jpg\n",
        "\n",
        "def convert_test(file,output_path):\n",
        "    print(file)\n",
        "    image = pydicom.dcmread(file)\n",
        "    image = image.pixel_array\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    out_path = os.path.join(output_path, f\"{file.rstrip('.dcm')}.jpg\")  # specifying the output file name by replacing the .dcm by .jpg of the original file\n",
        "    cv2.imwrite(out_path, image)\n",
        "\n",
        "for file_name in os.listdir(dcm_path):  # itterating over the files in the folder that contains the dcm test files\n",
        "    file_path = os.path.join(dcm_path, file_name)\n",
        "    convert_test(file_path,images_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zbTB4iIXc_Y"
      },
      "source": [
        "We itterate over the files in the folder that contains the dcm test images, converting them to jpg, resizing them and converting them to RGB, then saving them by replacing the .dcm to .jpg as the file names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0WoU4mRYXTl"
      },
      "source": [
        "After creating the jpg images, we create a folder named yolov4. Inside it, we create another folder named dataset then copy the created train jpg images to this folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC29LItRa8qm"
      },
      "source": [
        "# Creating txt files inside the dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3ixvSQVX0_W"
      },
      "outputs": [],
      "source": [
        "train_images = '/content/drive/MyDrive/yolov4/dataset'\n",
        "\n",
        "# Creating txt file for each image\n",
        "\n",
        "# We will create bounding boxes where the target is 1\n",
        "df_target_1 = df[df['Target'] == 1]\n",
        "\n",
        "# Create empty text files where the target is 0\n",
        "df_target_0 = df[df['Target'] == 0]\n",
        "\n",
        "# Loop over each jpg image in train_images\n",
        "for filename in os.listdir(train_images):\n",
        "    if filename.endswith('.jpg'):\n",
        "\n",
        "        # Get the patientId from the image filename\n",
        "        patient_id = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Find the patientId in the dataframe for target=1\n",
        "        rows_target_1 = df_target_1[df_target_1['patientId'] == patient_id]\n",
        "\n",
        "        if not rows_target_1.empty:\n",
        "            # Create txt file with bounding box data\n",
        "            txt_filename = os.path.join(train_images, f\"{patient_id}.txt\")\n",
        "            with open(txt_filename, 'w') as txt_file:\n",
        "                for _, row in rows_target_1.iterrows():\n",
        "                    # Target, x, y, width, height\n",
        "                    target = row['Target']\n",
        "                    x = row['x']\n",
        "                    y = row['y']\n",
        "                    width = row['width']\n",
        "                    height = row['height']\n",
        "\n",
        "                    # Content for the txt file (in that order)\n",
        "                    content = f\"{target} {x} {y} {width} {height}\\n\"\n",
        "                    txt_file.write(content)\n",
        "\n",
        "        # Find the patientId in the dataframe for target=0\n",
        "        rows_target_0 = df_target_0[df_target_0['patientId'] == patient_id]\n",
        "\n",
        "        if not rows_target_0.empty:\n",
        "            # Create empty txt file\n",
        "            txt_filename = os.path.join(train_images, f\"{patient_id}.txt\")\n",
        "            with open(txt_filename, 'w') as txt_file:\n",
        "                pass  # Create an empty file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik19ZClMZC2m"
      },
      "source": [
        "We create two separate dataframes: one for targets = 1 and the other for targets = 0. For the df_target_1, we get the row with patientId similar to image name, create txt files with the same name, get it's row from the csv file and put inside the txt file the target and bounding box details in this format: Target, x, y, width, height. For the df_target_0, we create an empty txt file with the same name as the patientId."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKrXJYCcad4P"
      },
      "outputs": [],
      "source": [
        "# Creating train.txt and test.txt\n",
        "\n",
        "import os\n",
        "\n",
        "path_list = []\n",
        "\n",
        "# Path where the images are located\n",
        "directory = '/content/drive/MyDrive/yolov4/dataset'\n",
        "os.chdir(directory)\n",
        "\n",
        "# Go through all the image files in the directory\n",
        "for current_dir, dirs, files in os.walk(directory):\n",
        "    # Iterating through all the files\n",
        "    for f in files:\n",
        "        # Check if the file extension ends with '.jpg'\n",
        "        if f.endswith('.jpg'):\n",
        "            # Prepare file path to save into train.txt\n",
        "            file_loc = os.path.join(current_dir, f)\n",
        "            # Append the path data into list \"path_list\"\n",
        "            path_list.append(file_loc)\n",
        "\n",
        "\n",
        "# Divide the data into 80:20 ratio. Get 20% of data from path_list to write into the test.txt file\n",
        "path_list_test = path_list[:int(len(path_list) * 0.20)]\n",
        "\n",
        "# Delete the same 20% records from the path_list as that 20% data is in path_list_test now\n",
        "path_list = path_list[int(len(path_list) * 0.20):]\n",
        "\n",
        "# Create train.txt file and write 80% of data (lines) inside it.\n",
        "with open('train.txt', 'w') as train:\n",
        "    # Iterate through all the elements in the list\n",
        "    for i in path_list:\n",
        "        # Write the current path at the end of the file\n",
        "        #train.write(i + '\\n')\n",
        "        train.write(i)\n",
        "\n",
        "# Create test.txt file and write 20% of data (lines) inside it.\n",
        "with open('test.txt', 'w') as test:\n",
        "    # Iterate through all the elements in the list\n",
        "    for i in path_list_test:\n",
        "        # Write the current path at the end of the file\n",
        "        #test.write(i + '\\n')\n",
        "        test.write(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLj_tYnwcBGK"
      },
      "source": [
        "Next, we create the train.txt and test.txt files which contain the image paths. We first define a list, itterate over the images inside the data folder and appended their paths to the list, then split this list into 80% train and 20% test (validation). We save the 20% of test into a new list and kept the original list for the train paths only. Then we created 2 txt files, one for the train named train.txt where we saved the paths from the list, the other is for the test named test.txt where we saved the paths from the test list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjLKHTEFe82E"
      },
      "source": [
        "# Clone the darknet repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dWm1_E5fWgr"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/yolov4\n",
        "\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHeDo8DQfboD"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/yolov4/darknet\n",
        "\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAM2b2Uk1GMf"
      },
      "source": [
        "Inside our yolov4 folder, we clone darknet from the darknet github repository, then change the current directory to the darknet folder and run the !make command which navigates to the darknet framework and compiles it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6YncT-x1NTn"
      },
      "source": [
        "Inside the yolov4 folder, we create a folder named custom_weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ_5quv01g-8"
      },
      "source": [
        "Inside darknet/makefile: change GPU, CUDNN, and OPENCV to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owD-66ygikGI"
      },
      "outputs": [],
      "source": [
        "%cd /content/MyDrive/yolov4/custom_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXzM8tDyfcTG"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuPQ1FRSf4ao"
      },
      "source": [
        "\n",
        "We change the current working directory to the custom_weight folder and download yolov4.conv.137 file, which contains pretrained weights for the convolutuon layers in it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZzoTTc7dI8x"
      },
      "source": [
        "# Creating classes.names and image_data.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajIJ1RQ-iru8"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/yolov4/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5crjljHudM9B"
      },
      "outputs": [],
      "source": [
        "# inside the dataset folder\n",
        "class_names = [\"Pneumonia\", \"Normal\"]\n",
        "train_txt_path = '/content/drive/MyDrive/yolov4/dataset/train.txt'\n",
        "test_txt_path = '/content/drive/MyDrive/yolov4/dataset/test.txt'\n",
        "\n",
        "# Create classes.names file\n",
        "names_file_path = '/content/drive/MyDrive/yolov4/dataset/classes.names'\n",
        "with open(names_file_path, 'w') as file:\n",
        "    for name in class_names:\n",
        "        file.write(name + '\\n')\n",
        "\n",
        "# Paths for the image_data.data file\n",
        "names_file = '/content/drive/MyDrive/yolov4/dataset/classes.names'\n",
        "backup_directory = '/content/drive/MyDrive/yolov4/darknet/backup'\n",
        "\n",
        "# Create image_data.data file\n",
        "obj_data_path = '/content/drive/MyDrive/yolov4/dataset/image_data.data'\n",
        "\n",
        "with open(obj_data_path, 'w') as file:\n",
        "    file.write(f\"classes = 2\\n\")\n",
        "    file.write(f\"train = {train_txt_path}\\n\")\n",
        "    file.write(f\"valid = {test_txt_path}\\n\")\n",
        "    file.write(f\"names = {names_file}\\n\")\n",
        "    file.write(f\"backup = {backup_directory}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyDCSHa0dTGI"
      },
      "source": [
        "For the classes names we have Pneumonia class and Normal class, we create a classes.names file where we saved the classes names. We then created the images_data.data file were we saved the the number of classes, the train.txt path, the test.txt path, the classes.names path, and the path of the backup directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HESqYQNjPux"
      },
      "source": [
        "Inside the darknet/cfg folder, we create a new file named yolov4_custom.cfg, then we copy the contents of the yolov4.cfg file from the darknet/cfg folder and paste it to the new yolov4_custom.cfg file we created. We then change the following parameters in yolov4_custom.cfg: batch=64, subdivision=16, max_batches= 4000, steps= 3200, 3600, filter=21, width=224, height=224, classes=2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xHnHNDeg-Tf"
      },
      "source": [
        "# Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmNqzRz4hCD2"
      },
      "outputs": [],
      "source": [
        "!./darknet detector train /content/drive/MyDrive/yolov4/dataset/image_data.data /content/drive/MyDrive/yolov4/darknet/cfg/yolov4_custom.cfg /content/drive/MyDrive/yolov4/custom_weight/yolov4.conv.137 -dont_show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdNEG2c6hG6q"
      },
      "source": [
        "We call the train command for the model and give it the images_data.data file path, the yolov4_custom.cfg file, and the yolov4.conv.137 weights file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z_AXyx_kPJd"
      },
      "outputs": [],
      "source": [
        "# to continue training after it disconnects\n",
        "\n",
        "!./darknet detector train /content/drive/MyDrive/study/darknet/data/train/image_data.data /content/drive/MyDrive/study/darknet/cfg/yolov4_custom.cfg  /content/drive/MyDrive/study/darknet/backup/yolov4_custom_last.weights -dont_show -map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j688zj_kTpT"
      },
      "source": [
        "In case of disconnection during training, we will continue training using this command, with the modification of the weights file were we gave it the path of the last weights of the training before it disconnected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxSBBbi9k8gv"
      },
      "source": [
        "After training is done, the following files are created in darknet/backup folder: yolov4_custom_last.weights, yolov4_custom_1000.weights, yolov4_custom_2000.weights, yolov4_custom_3000.weights, yolov4_custom_4000.weights, yolov4_custom_final.weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"chart.png\" style=\"width:500px; height:500px;\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLdQ8V1jk2um"
      },
      "source": [
        "# Testing (Prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph4an-sbk5Rf"
      },
      "outputs": [],
      "source": [
        "# Open the configuration file\n",
        "\n",
        "with open('/content/drive/MyDrive/yolov4/darknet/cfg/yolov4_custom.cfg', 'r') as file:\n",
        "    data = file.readlines()\n",
        "\n",
        "# Iterate through the lines of the file\n",
        "for i, line in enumerate(data):\n",
        "    # Find lines with 'batch_normalize=1' and replace them with 'batch_normalize=0'\n",
        "    if 'batch_normalize=1' in line:\n",
        "        data[i] = line.replace('batch_normalize=1', 'batch_normalize=0')\n",
        "    # Find lines with 'subdivisions=' and replace the value with '1'\n",
        "    elif 'subdivisions=' in line:\n",
        "        data[i] = 'subdivisions=1\\n'\n",
        "    # Find lines with 'batch=' and replace the value with '1'\n",
        "    elif 'batch=' in line:\n",
        "        data[i] = 'batch=1\\n'\n",
        "\n",
        "# Write the modified data back to the file\n",
        "with open('/content/drive/MyDrive/yolov4/darknet/cfg/yolov4_custom.cfg', 'w') as file:\n",
        "    file.writelines(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLlh5ZlEk5-u"
      },
      "source": [
        "We change the following parameters in yolov4_custom.cfg to prepare for testing: batch=1, subdivision=1, batch_normalize=0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liDKRxJDlzzt"
      },
      "outputs": [],
      "source": [
        "!./darknet detector test /content/drive/MyDrive/yolov4/dataset/image_data.data /content/drive/MyDrive/yolov4/darknet/cfg/yolov4_custom.cfg /content/drive/MyDrive/yolov4/custom_weight/yolov4_custom_final.weights /content/drive/MyDrive/yolov4/normal.jpg -out result.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if you get error permission denied, run this then run the previous cell\n",
        "\n",
        "!chmod +x ./darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcw0DaRhl4sM"
      },
      "source": [
        "For the test command we give it the image_data.data file path, the yolov4_custom.cfg file path, the yolov4_custom_final.weights file path, and the path to the test file (from the original test file provided). We also specified the result ouput file so that the output results of the test would be saved in a txt file named result.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('predictions.jpg')\n",
        "\n",
        "results_file = 'result.txt'\n",
        "\n",
        "with open(results_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Parse each line to get bounding box coordinates, confidence, and class\n",
        "results = []\n",
        "for line in lines:\n",
        "    # Example format: \"class, confidence, x_min, y_min, x_max, y_max\"\n",
        "    parts = line.strip().split(',')  #read each line of the text file\n",
        "    class_name = parts[0]   #get the class name\n",
        "    confidence = float(parts[1]) #get the confidence \n",
        "    coords = list(map(int, parts[2:])) #get the x min , y min , x max , y max and put them into a list\n",
        "    x_min, y_min, x_max, y_max = coords #then assign a variable for each value of this list\n",
        "    results.append({\"class\": class_name, \"confidence\": confidence, \"bbox\": [x_min, y_min, x_max, y_max]})  #append the results retrived from the file to the list\n",
        "\n",
        "# Draw bounding boxes and labels only for class \"pneumonia\"\n",
        "for result in results:  #loop over the list\n",
        "    if result[\"class\"] == \"pneumonia\":   #we will draw the bounding box only if the pneumonia present\n",
        "        class_name = result[\"class\"]  #get class name \"pneumonia\"\n",
        "        confidence = result[\"confidence\"] #get the confidence\n",
        "        bbox = result[\"bbox\"] #get the bounding box (xmin,ymin,xmax,ymax)\n",
        "        x_min, y_min, x_max, y_max = bbox  #assign a variable for each value in the bounding box\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)  #draw the rectangle on the image\n",
        "        label = f\"{class_name}: {confidence:.2f}\"  #label the rectangle with the class name and the confidence\n",
        "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) #put the label and confidence on the image\n",
        "\n",
        "# Display or save the image with annotations\n",
        "cv2.imshow('Image with Annotations', image)  \n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# To save the image:\n",
        "cv2.imwrite('annotated_image.jpg', image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use OpenCV to load the predicted image , read detection results from the result.txt file, and annotate the image with bounding boxes for class \"Pneumonia\". We extract the (class name, confidence, x_min, y_min, x_max, y_max) then store them in a list. The annotated image is displayed using a window and saved to a file named annotated_image.jpg."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
